\# Lab 4 -- HBase & Spark

\## Objectifs du TP

1\. Charger un dataset dans HDFS 2. Cr√©er et alimenter une table HBase
3. Interroger et v√©rifier les donn√©es 4. Int√©grer Spark pour analyser
les donn√©es distribu√©es

\-\--

\## üìÇ Structure du projet

\`\`\` Lab4_HBase/ ‚îÇ ‚îú‚îÄ‚îÄ HelloHBase.java \# Code Java pour HBase
(cr√©ation + insertion + lecture) ‚îú‚îÄ‚îÄ purchases_2.txt \# Dataset (NON
inclus GitHub car \>100MB) ‚îú‚îÄ‚îÄ Screenshots/ \# Captures d'√©cran de
l'ex√©cution ‚îî‚îÄ‚îÄ hbase_spark/ ‚îú‚îÄ‚îÄ HbaseSparkProcess.java ‚îî‚îÄ‚îÄ
HbaseSparkAnalytics.java \`\`\`

\-\--

\## Partie 1 --- HBase

\### Dataset utilis√©

\`\`\` purchases_2.txt \`\`\`

‚ö† \*\*Non ajout√© √† GitHub\*\* (taille : 232MB, limite GitHub = 100MB)

\-\--

\## √âtapes r√©alis√©es

\### ‚úî 1. Import du dataset dans Docker

Le fichier \`purchases_2.txt\` a √©t√© copi√© dans le conteneur via un
volume Docker.

\### ‚úî 2. Cr√©ation de la table HBase

Commande ex√©cut√©e dans le shell HBase :

\`\`\`hbase create \'products\', \'cf\' \`\`\`

\### ‚úî 3. Insertion et lecture via Java

Le fichier \`HelloHBase.java\` effectue :

\* Connexion au cluster HBase \* Cr√©ation de table (si inexistante) \*
Insertion de plusieurs lignes d'exemple \* Lecture et affichage des
donn√©es

Fichier : \`Lab4_HBase/HelloHBase.java\`

\-\--

\## Partie 2 --- Spark + HBase

\*\*Objectif :\*\* lire les donn√©es stock√©es dans la table HBase et
effectuer des analyses distribu√©es.

\### Scripts inclus

\#### HbaseSparkProcess.java

Lit la table HBase \`products\` via Spark :

\* Configuration HBase \* Utilisation de \`TableInputFormat\` \*
Comptage des lignes de la table

Fichier : \`Lab4_HBase/hbase_spark/HbaseSparkProcess.java\`

\-\--

\#### HbaseSparkAnalytics.java

Script Spark complet permettant :

\* Somme totale de toutes les ventes \* Total des ventes par produit \*
Total des ventes par ville \* Statistiques globales :

\* min \* max \* moyenne

Fichier : \`Lab4_HBase/hbase_spark/HbaseSparkAnalytics.java\`

\-\--

\## R√©sultats obtenus

\### Avec HBase :

\* Table \`products\` cr√©√©e et correctement aliment√©e \* Lectures OK \*
V√©rification de la pr√©sence des lignes : success

\### Avec Spark :

\* RDD cr√©√© depuis HBase \* Nombre total de lignes affich√© \* Calculs
distribu√©s effectu√©s :

\* Total ventes = OK \* Ventes par produit = OK \* Ventes par ville = OK
\* Statistiques globales = OK

\-\--

\## Conclusion

Ce TP a permis de :

\* Manipuler un dataset volumineux dans HDFS \* G√©rer des donn√©es NoSQL
avec HBase \* Int√©grer Spark pour analyser des donn√©es distribu√©es \*
D√©velopper des programmes Java pour interagir avec HBase et Spark

\-\--
